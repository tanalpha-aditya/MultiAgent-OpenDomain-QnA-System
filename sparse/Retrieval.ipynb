{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import numpy as np\n","from nltk import word_tokenize\n","import copy\n","from collections import defaultdict\n","from tqdm import tqdm\n","import math"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def preprocess(unit):\n","    remove = ['.', ',', '!', '?', '[', ']', '{', '}', '(', ')', '*', '&', '#', ':', ';', '\"', \"'\", '-', '+', '_', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n","    remove2= ['\\n', '”', '“', '’']\n","    unit2 = copy.deepcopy(unit)\n","    for c in remove:\n","        unit2 = unit2.replace(c, '')\n","    for c in remove2:\n","        unit2 = unit2.replace(c, ' ')\n","    unit = unit2\n","    words = word_tokenize(unit)\n","    words2 = []\n","    for word in words:\n","        word = word.lower()\n","        words2.append(word)\n","    return words2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_documents_tokenized(path):\n","    documents = []\n","    documents_tokenized = []\n","    for filename in os.listdir(path):\n","        file_path = os.path.join(path, filename)\n","        if os.path.isfile(file_path):\n","            with open(file_path, \"r\") as f:\n","                content = f.read()\n","                documents.append(content)\n","    for document in documents:\n","        documents_tokenized.append(preprocess(document))\n","    return documents_tokenized"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train_tf_idf(path):\n","    documents_tokenized = get_documents_tokenized(path)\n","    tf = defaultdict(lambda: {})\n","    freq = defaultdict(lambda: 0)\n","    for i in tqdm(range(len(documents_tokenized))):\n","        tf[i] = defaultdict(lambda: 0)\n","        tokens = documents_tokenized[i]\n","        for token in tokens:\n","            freq[token] += 1\n","            tf[i][token] += 1\n","\n","    for i in tqdm(range(len(documents_tokenized))):\n","        for token in tf[i].keys():\n","            tf[i][token] = tf[i][token] / len(documents_tokenized[i])\n","    \n","    idf = defaultdict(lambda: 0)\n","    ndoc = defaultdict(lambda: 0)\n","    for i in tqdm(range(len(documents_tokenized))):\n","        temp = defaultdict(lambda: 0)\n","        tokens = documents_tokenized[i]\n","        for token in tokens:\n","            if(temp[token] == 0):\n","                idf[token] += 1\n","                temp[token] += 1\n","\n","    for token in tqdm(idf.keys()):\n","        ndoc[token] = idf[token]\n","        idf[token] = math.log(len(documents_tokenized) / idf[token])\n","\n","    tf_idf = defaultdict(lambda: 0)\n","    for i in tqdm(range(len(documents_tokenized))):\n","        tf_idf[i] = defaultdict(lambda: 0)\n","        for token in documents_tokenized[i]:\n","            tf_idf[i][token] = tf[i][token] * idf[token]\n","    \n","    return tf_idf, idf, ndoc, tf, documents_tokenized"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_tf_query(query):\n","    k = len(query)\n","    tf_query = defaultdict(lambda: 0)\n","    for i in range(k):\n","        tf_query[query[i]] += 1\n","    for token in tf_query.keys():\n","        tf_query[token] /= k\n","    return tf_query\n","\n","def get_tf_idf_query(query, idf_dict):\n","    query = preprocess(query)\n","    tf_idf_query = defaultdict(lambda: 0)\n","    tf_query = get_tf_query(query)\n","    for token in tf_query.keys():\n","        tf_idf_query[token] = tf_query[token] * idf_dict[token]\n","    return tf_idf_query\n","\n","def cosine_similarity(v1, v2):\n","    v1 = np.array(v1)\n","    v2 = np.array(v2)\n","    sim = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n","\n","def tf_idf_rankings(query, idf_dict, tf_idf_dict):\n","    query_vector = get_tf_idf_query(query, idf_dict)\n","    scores = []\n","    for i in tqdm(range(len(list(tf_idf_dict.keys())))):\n","        document_vector = tf_idf_dict[i]\n","        scores.append((i, cosine_similarity(document_vector, query_vector)))\n","    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n","    return scores"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sentence-transformers in /home/pranit/.local/lib/python3.10/site-packages (3.1.1)\n","Requirement already satisfied: transformers<5.0.0,>=4.38.0 in /home/pranit/.local/lib/python3.10/site-packages (from sentence-transformers) (4.45.1)\n","Requirement already satisfied: Pillow in /home/pranit/.local/lib/python3.10/site-packages (from sentence-transformers) (10.4.0)\n","Requirement already satisfied: scikit-learn in /home/pranit/.local/lib/python3.10/site-packages (from sentence-transformers) (1.5.2)\n","Requirement already satisfied: huggingface-hub>=0.19.3 in /home/pranit/.local/lib/python3.10/site-packages (from sentence-transformers) (0.25.1)\n","Requirement already satisfied: tqdm in /home/pranit/.local/lib/python3.10/site-packages (from sentence-transformers) (4.66.5)\n","Requirement already satisfied: torch>=1.11.0 in /home/pranit/.local/lib/python3.10/site-packages (from sentence-transformers) (2.4.1)\n","Requirement already satisfied: scipy in /home/pranit/.local/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (5.4.1)\n","Requirement already satisfied: requests in /home/pranit/.local/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/pranit/.local/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.12.2)\n","Requirement already satisfied: filelock in /home/pranit/.local/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /home/pranit/.local/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /home/pranit/.local/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (24.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/pranit/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/pranit/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/pranit/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/pranit/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/pranit/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/pranit/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n","Requirement already satisfied: triton==3.0.0 in /home/pranit/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.0.0)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/pranit/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n","Requirement already satisfied: sympy in /home/pranit/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/pranit/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/pranit/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n","Requirement already satisfied: jinja2 in /home/pranit/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/pranit/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n","Requirement already satisfied: networkx in /home/pranit/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/pranit/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/pranit/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.77)\n","Requirement already satisfied: regex!=2019.12.17 in /home/pranit/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (2024.9.11)\n","Requirement already satisfied: numpy>=1.17 in /home/pranit/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (1.26.4)\n","Requirement already satisfied: safetensors>=0.4.1 in /home/pranit/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/pranit/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.20.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/pranit/.local/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/pranit/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.3.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2020.6.20)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (1.26.5)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.3)\n","Requirement already satisfied: joblib>=1.2.0 in /home/pranit/.local/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /home/pranit/.local/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/pranit/.local/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"]}],"source":["!pip install sentence-transformers"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/pranit/.local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from tqdm.autonotebook import tqdm, trange\n"]}],"source":["from sentence_transformers import SentenceTransformer, util"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/pranit/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}],"source":["# Load the model\n","model = SentenceTransformer('all-MiniLM-L6-v2')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_open_source_embeddings(path):\n","    documents = []\n","    for filename in os.listdir(path):\n","        file_path = os.path.join(path, filename)\n","        if os.path.isfile(file_path):\n","            with open(file_path, \"r\") as f:\n","                content = f.read()\n","                documents.append(content)\n","    documents_embeddings = model.encode(documents)\n","    return documents_embeddings\n","    \n","def open_source_rankings(query, document_embeddings):\n","    query_embedding = model.encode(query)\n","    scores = []\n","    for idx, embedding in enumerate(document_embeddings):\n","        scores.append((cosine_similarity(query_embedding, embedding), idx))\n","    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n","    return scores"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def IDF(token, ndoc_dict, document_set):\n","    k = math.log(((len(document_set) - ndoc_dict[token] + 0.5) / (ndoc_dict[token] + 0.5)) + 1)\n","    return k\n","\n","def get_avgdl(document_set):\n","    sum = 0\n","    for document in document_set:\n","        sum = sum + len(document)\n","    sum = sum / len(document_set)\n","    return sum\n","\n","k1 = 1.75\n","b = 0.75\n","\n","def bm25(query, document_number, document_set, tf_dict, ndoc_dict, avgdl):\n","    sum = 0\n","    for token in query:\n","        f = tf_dict[document_number][token]\n","        idf_query = IDF(token, ndoc_dict, document_set)\n","        sum = sum + ((idf_query * f * (k1 + 1)) / (f + (k1 * (1 - b + (b * (len(document_set[document_number]) / avgdl))))))\n","    return sum\n","\n","def get_bm25_rankings(query, documents_tokenized, tf_dict):\n","    avgdl = get_avgdl(documents_tokenized)\n","    query = preprocess(query)\n","    scores = []\n","    for idx, document in enumerate(documents_tokenized):\n","        scores.append((idx, bm25(query, idx, documents_tokenized, tf_dict, avgdl)))\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5933752,"sourceId":9702874,"sourceType":"datasetVersion"},{"datasetId":5937184,"sourceId":9707446,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"vscode":{"interpreter":{"hash":"e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"}}},"nbformat":4,"nbformat_minor":4}
