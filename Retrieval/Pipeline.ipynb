{"cells":[{"cell_type":"code","execution_count":14,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-11-18T16:00:16.420107Z","iopub.status.busy":"2024-11-18T16:00:16.419652Z","iopub.status.idle":"2024-11-18T16:00:43.803105Z","shell.execute_reply":"2024-11-18T16:00:43.801754Z","shell.execute_reply.started":"2024-11-18T16:00:16.420062Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","\u001b[33mWARNING: Ignoring invalid distribution -qdm (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qdm (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: gensim in /home/pranit/.local/lib/python3.10/site-packages (4.3.3)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n","Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.24.1)\n","Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.0)\n","\u001b[33mWARNING: Ignoring invalid distribution -qdm (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install gensim"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","\u001b[33mWARNING: Ignoring invalid distribution -qdm (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qdm (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: sentence-transformers in /home/pranit/.local/lib/python3.10/site-packages (3.3.1)\n","Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from sentence-transformers) (9.0.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.10.0)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /home/pranit/.local/lib/python3.10/site-packages (from sentence-transformers) (0.26.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.1)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/pranit/.local/lib/python3.10/site-packages (from sentence-transformers) (4.46.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.7.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (5.4.1)\n","Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.25.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.6.0)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.10.3.66)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (8.5.0.96)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.99)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.9.0.58)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.14.3)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.101)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.91)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.2.10.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.0.0)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.0.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n","Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11.0->sentence-transformers) (0.37.1)\n","Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11.0->sentence-transformers) (59.6.0)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->sentence-transformers) (16.0.6)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->sentence-transformers) (3.27.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.24.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /home/pranit/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.8.8)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/pranit/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.2.1)\n","\u001b[33mWARNING: Ignoring invalid distribution -qdm (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install sentence-transformers"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","\u001b[33mWARNING: Ignoring invalid distribution -qdm (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qdm (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mCollecting rank-bm25\n","  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank-bm25) (1.24.1)\n","\u001b[33mWARNING: Ignoring invalid distribution -qdm (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: rank-bm25\n","Successfully installed rank-bm25-0.2.2\n"]}],"source":["!pip install rank-bm25"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","\u001b[33mWARNING: Ignoring invalid distribution -qdm (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qdm (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: fpdf in /home/pranit/.local/lib/python3.10/site-packages (1.7.2)\n","\u001b[33mWARNING: Ignoring invalid distribution -qdm (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install fpdf"]},{"cell_type":"code","execution_count":30,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","from nltk import word_tokenize\n","import copy\n","from collections import defaultdict\n","from tqdm import tqdm\n","import math\n","import json\n","from gensim.utils import simple_preprocess\n","import joblib\n","from sentence_transformers import SentenceTransformer, util\n","from rank_bm25 import BM25Okapi\n","from transformers import ViTModel, ViTFeatureExtractor, ViTImageProcessor\n","from PIL import Image\n","import torch\n","from fpdf import FPDF\n","from datetime import datetime\n","import fitz"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[],"source":["import random\n","\n","def get_documents():\n","    ids = []\n","    documents = []\n","    with open('/kaggle/input/project-data/mini_wiki_collection.json', \"r\") as f:\n","        data = json.load(f)\n","        for item in data:\n","            ids.append(item[\"_id\"])\n","            temp = \"\"\n","            for text in item[\"text\"]:\n","                if(text[-1] == '\\n'):\n","                    temp = temp + text[:-1] + \" \"\n","                else:\n","                    temp = temp + text + \" \"\n","            documents.append(temp)\n","    return ids, documents\n","\n","def get_random_documents(n, ids=[]):\n","    if(ids == []):\n","        ids = []\n","        documents = []\n","        with open('/kaggle/input/miniwiki/mini_wiki_collection_10000_documents (1).json', \"r\") as f:\n","            data = json.load(f)\n","            for item in data:\n","                ids.append(item[\"_id\"])\n","                temp = \"\"\n","                for text in item[\"text\"]:\n","                    if(text[-1] == '\\n'):\n","                        temp = temp + text[:-1] + \" \"\n","                    else:\n","                        temp = temp + text + \" \"\n","                documents.append(temp)\n","        random_numbers = random.sample(range(10000), n)\n","        ids2 = []\n","        documents2 = []\n","        for random_number in random_numbers:\n","            ids2.append(ids[random_number])\n","            documents2.append(documents[random_number])\n","        return ids2, documents2\n","    else:\n","        ids2 = ids\n","        ids3 = []\n","        documents3 = []\n","        documents2 = []\n","        with open('/kaggle/input/miniwiki/mini_wiki_collection_10000_documents (1).json', \"r\") as f:\n","            data = json.load(f)\n","            for item in data:\n","                ids3.append(item[\"_id\"])\n","                temp = \"\"\n","                for text in item[\"text\"]:\n","                    if(text[-1] == '\\n'):\n","                        temp = temp + text[:-1] + \" \"\n","                    else:\n","                        temp = temp + text + \" \"\n","                documents3.append(temp)\n","            for id in ids2:\n","                for i in range(len(ids3)):\n","                    if(ids3[i] == id):\n","                        documents2.append(documents3[i])\n","        return ids2, documents2"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["def get_documents_tokenized_from_file(path, random=0, ids2=[]):\n","    documents = []\n","    queries = []\n","    modified_queries = []\n","    documents_tokenized = []\n","    ids = []\n","    queries_ids = []\n","    ids, documents = get_documents()\n","    ids2, documents2 = get_random_documents(random, ids2)\n","    ids = ids + ids2\n","    documents = documents + documents2\n","    with open(path, \"r\") as f:\n","        content = json.load(f)\n","        for key in content.keys():\n","            # documents.append(list(content[key][\"output\"].values())[0][0])\n","            queries.append(content[key][\"input\"])\n","            queries_ids.append(key)\n","            modified_queries.append(content[key][\"modified_query\"])\n","        # documents.append(content)\n","    for idx, document in tqdm(enumerate(documents)):\n","        documents_tokenized.append(simple_preprocess(document))\n","    return documents_tokenized, documents, queries, modified_queries, ids, queries_ids, ids2, documents2"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["documents_tokenized, documents, queries, modified_queries, ids, queries_ids, ids2, documents2 = get_documents_tokenized_from_file('/kaggle/input/project-data/FinalDataset_WithModifiedQuery.json')"]},{"cell_type":"code","execution_count":34,"metadata":{"trusted":true},"outputs":[],"source":["def get_documents_from_scores(scores):\n","    rankings = []\n","    for score in scores:\n","        rankings.append(score[0])\n","    return rankings"]},{"cell_type":"code","execution_count":32,"metadata":{"trusted":true},"outputs":[],"source":["def train_tf_idf(documents_tokenized):\n","    # documents_tokenized = get_documents_tokenized(path)\n","    vocab = {}\n","    tf = defaultdict(lambda: {})\n","    freq = defaultdict(lambda: 0)\n","    for i in tqdm(range(len(documents_tokenized))):\n","        tf[i] = defaultdict(lambda: 0)\n","        tokens = documents_tokenized[i]\n","        for token in tokens:\n","            freq[token] += 1\n","            tf[i][token] += 1\n","            if token not in vocab:\n","                vocab[token] = 1\n","\n","    for i in tqdm(range(len(documents_tokenized))):\n","        for token in tf[i].keys():\n","            tf[i][token] = tf[i][token] / len(documents_tokenized[i])\n","    \n","    idf = defaultdict(lambda: 0)\n","    ndoc = defaultdict(lambda: 0)\n","    for i in tqdm(range(len(documents_tokenized))):\n","        temp = defaultdict(lambda: 0)\n","        tokens = documents_tokenized[i]\n","        for token in tokens:\n","            if(temp[token] == 0):\n","                idf[token] += 1\n","                temp[token] += 1\n","\n","    for token in tqdm(idf.keys()):\n","        ndoc[token] = idf[token]\n","        idf[token] = math.log(len(documents_tokenized) / idf[token])\n","\n","    tf_idf = defaultdict(lambda: 0)\n","    for i in tqdm(range(len(documents_tokenized))):\n","        tf_idf[i] = defaultdict(lambda: 0)\n","        for token in documents_tokenized[i]:\n","            tf_idf[i][token] = tf[i][token] * idf[token]\n","    \n","    return tf_idf, idf, ndoc, tf, vocab\n","def get_tf_query(query):\n","    k = len(query)\n","    tf_query = defaultdict(lambda: 0)\n","    for i in range(k):\n","        tf_query[query[i]] += 1\n","    for token in tf_query.keys():\n","        tf_query[token] /= k\n","    return tf_query\n","\n","def get_tf_idf_query(query, idf_dict):\n","    query = simple_preprocess(query)\n","    tf_idf_query = defaultdict(lambda: 0)\n","    tf_query = get_tf_query(query)\n","    for token in tf_query.keys():\n","        tf_idf_query[token] = tf_query[token] * idf_dict[token]\n","    return tf_idf_query\n","    \n","def get_tf_idf_vector(tf_idf_instance, vocab):\n","    temp = []\n","    for key in vocab.keys():\n","        temp.append(tf_idf_instance[key])\n","    return temp\n","    \n","def cosine_similarity(v1, v2):\n","    v1 = np.array(v1)\n","    v2 = np.array(v2)\n","    if(np.linalg.norm(v1) != 0 and np.linalg.norm(v2) != 0):\n","        sim = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n","    else:\n","        sim = 0\n","    return sim\n","\n","def print_non_zero(dict):\n","    for key in dict.keys():\n","        if(dict[key] > 0):\n","            print(dict[key])\n","\n","def get_document_vectors(tf_idf_dict, vocab):\n","    document_vectors = []\n","    for i in tqdm(range(len(list(tf_idf_dict.keys())))):\n","        document_vector = get_tf_idf_vector(tf_idf_dict[i], vocab)\n","        document_vectors.append(document_vector)\n","    return document_vectors\n","\n","\n","def tf_idf_rankings(query, idf_dict, tf_idf_dict, vocab, document_matrix, k):\n","    query_vector = np.reshape(np.array(get_tf_idf_vector(get_tf_idf_query(query, idf_dict), vocab)), (1, -1))\n","    scores = []\n","    dot_products = document_matrix @ query_vector.T\n","\n","    query_norm = np.linalg.norm(query_vector)\n","    doc_norms = np.linalg.norm(document_matrix, axis=1, keepdims=True)\n","    cosine_similarities = dot_products / (doc_norms * query_norm)\n","    cosine_similarities = cosine_similarities.flatten()\n","    rankings = np.argsort(cosine_similarities)[::-1]\n","    rankings = rankings[:k]\n","    scores = []\n","    for rank in rankings:\n","        scores.append(cosine_similarities[rank])\n","    # scores = sorted(cosine_similarities, key=lambda x: x[1], reverse=True)\n","    # scores = scores[:k]\n","    # rankings = get_documents_from_scores(scores)\n","    return rankings, scores\n","def tf_idf_pipeline(query, idf_dict_path, tf_idf_dict_path, vocab_path, document_matrix_path, ids_path, k):\n","    idf_dict = joblib.load(idf_dict_path)\n","    print(\"idf loaded...\")\n","    tf_idf_dict = joblib.load(tf_idf_dict_path)\n","    print(\"tf-idf loaded...\")\n","    vocab = joblib.load(vocab_path)\n","    print(\"vocab loaded...\")\n","    document_matrix = joblib.load(document_matrix_path)\n","    print(\"document_matrix loaded...\")\n","    ids = joblib.load(ids_path)\n","    print(\"ids loaded\")\n","    rankings, scores = tf_idf_rankings(query, idf_dict, tf_idf_dict, vocab, document_matrix, k)\n","    rankings2 = []\n","    for ranking in tqdm(rankings):\n","        rankings2.append(ids[ranking])\n","    return rankings2"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["idf loaded...\n","tf-idf loaded...\n","vocab loaded...\n","document_matrix loaded...\n","ids loaded\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5/5 [00:00<00:00, 117159.33it/s]\n"]},{"data":{"text/plain":["['54376', '2015257', '24113', '189842', '21489431']"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["tf_idf_pipeline(\"In the United States, why are positions like Attorney General, Secretary of State, etc. appointed by the president at the federal level but elected by the people at the state level? Had it ever been proposed to do this differently?\", 'idf (1).pkl', 'tf_idf_dict (3).pkl', 'vocab.pkl', 'document_matrix.pkl', 'ids.pkl', 5)"]},{"cell_type":"code","execution_count":39,"metadata":{"trusted":true},"outputs":[],"source":["# Load the model\n","model = SentenceTransformer('all-MiniLM-L6-v2')"]},{"cell_type":"code","execution_count":41,"metadata":{"trusted":true},"outputs":[],"source":["def get_open_source_embeddings(documents):\n","    documents_embeddings = []\n","    for document in tqdm(documents):\n","        documents_embeddings.append(model.encode(document))\n","    return documents_embeddings\n","    \n","def open_source_rankings(query, document_embeddings, k):\n","    query_embedding = model.encode(query)\n","    scores = []\n","    for idx, embedding in enumerate(document_embeddings):\n","        scores.append((idx, cosine_similarity(query_embedding, embedding)))\n","    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n","    scores = scores[:k]\n","    rankings = get_documents_from_scores(scores)\n","    return rankings, scores\n","def open_source_pipeline(query, documents_embeddings_path, ids_path, k):\n","    document_embeddings = joblib.load(documents_embeddings_path)\n","    ids = joblib.load(ids_path)\n","    rankings, scores = open_source_rankings(query, document_embeddings, k)\n","    rankings2 = []\n","    for ranking in tqdm(rankings):\n","        rankings2.append(ids[ranking])\n","    return rankings2"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 5/5 [00:00<00:00, 102801.57it/s]\n"]},{"data":{"text/plain":["['54376', '2015257', '31739', '24113', '31187327']"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["open_source_pipeline(\"In the United States, why are positions like Attorney General, Secretary of State, etc. appointed by the president at the federal level but elected by the people at the state level? Had it ever been proposed to do this differently?\", 'open_source_embeddings.pkl', 'ids.pkl', 5)"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[],"source":["def bm25_pipeline(query, bm25_path, ids_path, k):\n","    bm25 = joblib.load(bm25_path)\n","    ids = joblib.load(ids_path)\n","    ranking = bm25.get_scores(simple_preprocess(query))\n","    ranking = np.argsort(np.array(ranking))[::-1]\n","    ranking = ranking[:k]\n","    for j in range(len(ranking)):\n","        ranking[j] = ids[ranking[j]]\n","    return ranking"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["array([ 260962,  232530, 3414021,   54376, 2015257])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["bm25_pipeline(\"In the United States, why are positions like Attorney General, Secretary of State, etc. appointed by the president at the federal level but elected by the people at the state level? Had it ever been proposed to do this differently?\", 'bm25-1_0', 'ids.pkl', 5)"]},{"cell_type":"code","execution_count":27,"metadata":{"trusted":true},"outputs":[],"source":["def pdf_to_image(pdf_path, zoom=2.0):\n","    # Open the PDF file\n","    pdf_document = fitz.open(pdf_path)\n","    \n","    # Create a list to store image paths\n","    image_paths = []\n","    \n","    # Create an 'Images' directory if it doesn't exist\n","    os.makedirs(\"Images\", exist_ok=True)\n","    \n","    # Iterate over PDF pages and convert each to an image\n","    for page_num in range(len(pdf_document)):\n","        page = pdf_document.load_page(page_num)  # Load the page\n","        \n","        # Set zoom level to improve quality\n","        mat = fitz.Matrix(zoom, zoom)  # Create a transformation matrix with the zoom level\n","        pix = page.get_pixmap(matrix=mat)  # Render the page to an image with the specified zoom\n","        \n","        image_file = f'Images/{os.path.basename(pdf_path)}_page_{page_num}.png'\n","        pix.save(image_file)  # Save the image as PNG\n","        image_paths.append(image_file)\n","    \n","    # Return the list containing paths of all images\n","    return image_paths"]},{"cell_type":"code","execution_count":28,"metadata":{"trusted":true},"outputs":[],"source":["def create_pdf(input_text):\n","    # Create instance of FPDF class\n","    pdf = FPDF()\n","    \n","    # Add a page\n","    pdf.add_page()\n","    \n","    # Set font\n","    pdf.set_font(\"Arial\", size=10)\n","    \n","    # Split the input text into multiple lines if necessary\n","    # This ensures that the text fits the page and multiple pages are handled\n","    pdf.multi_cell(0, 5, txt=input_text)\n","    \n","    # Create a unique file name with the current time\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    file_name = f\"PDFs/Aditya_{timestamp}.pdf\"\n","    \n","    # Create output directory if it doesn't exist\n","    os.makedirs(os.path.dirname(file_name), exist_ok=True)\n","    \n","    # Save the PDF\n","    pdf.output(file_name)\n","    \n","    # Return the file path\n","    return file_name"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n","processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[],"source":["import re\n","\n","def sanitize_text(text):\n","    \"\"\"\n","    Cleans and standardizes text by keeping only alphanumeric characters and spaces.\n","    Args:\n","        text (str): Text to sanitize.\n","    Returns:\n","        str: Sanitized text.\n","    \"\"\"\n","    if isinstance(text, str):\n","        # Use regex to keep only alphanumeric characters and spaces\n","        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n","        # Optionally, collapse multiple spaces into a single space\n","        text = re.sub(r'\\s+', ' ', text).strip()\n","    return text\n","\n","def text_to_images(text):\n","    text = sanitize_text(text)\n","    pdf_path = create_pdf(text)\n","    image_paths = pdf_to_image(pdf_path)\n","    return image_paths"]},{"cell_type":"code","execution_count":37,"metadata":{"trusted":true},"outputs":[],"source":["def documents_to_images(path):\n","    document_set = []\n","    for filename in os.listdir(path):\n","        file_path = os.path.join(path, filename)\n","        if os.path.isfile(file_path):\n","            with open(file_path, \"r\") as f:\n","                content = f.read()\n","                document_set.append(content)\n","    document_image_paths = []\n","    for document in document_set:\n","        image_paths = text_to_images(document)\n","        document_image_paths.append(image_paths)\n","    return document_image_paths\n","\n","def single_unit_embedding(text):\n","    image_paths = text_to_images(text)\n","    temp = []\n","    for image_path in image_paths:\n","        image = Image.open(image_path)\n","        inputs = processor(images=image, return_tensors=\"pt\")\n","        outputs = model(**inputs)\n","        vector = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n","        temp.append(vector)\n","    return np.mean(np.array(temp), axis=0)\n","\n","def single_image_embedding(image):\n","    inputs = processor(images=image, return_tensors=\"pt\")\n","    outputs = model(**inputs)\n","    vector = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n","    return vector\n","\n","def documents_to_vision_embeddings(documents):\n","    document_vision_embeddings = []\n","    for document in tqdm(documents):\n","        vector = single_unit_embedding(document)\n","        document_vision_embeddings.append(vector)\n","    return document_vision_embeddings\n","\n","def queries_to_vision_embeddings(queries):\n","    query_vision_embeddings = []\n","    for query in tqdm(queries):\n","        vector = single_unit_embedding(query)\n","        query_vision_embeddings.append(vector)\n","    return query_vision_embeddings\n","\n","def vision_rankings(query_embedding, document_embeddings, k):\n","    # query_embedding = single_unit_embedding(query)\n","    scores = []\n","    for idx, embedding in enumerate(document_embeddings):\n","        scores.append((idx, cosine_similarity(query_embedding[0], embedding[0])))\n","    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n","    scores = scores[:k]\n","    rankings = get_documents_from_scores(scores)\n","    return rankings, scores\n","\n","def vision_pipeline(query, document_embeddings_path, ids_path, k):\n","    # document_embeddings = joblib.load(document_embeddings_path)\n","    ids = joblib.load(ids_path)\n","    documents_vision_embeddings2 = []\n","    with open(\"document-vision-embeddings.json\", \"r\") as f:\n","        document_vision_embeddings2 = json.load(f)\n","    document_vision_embeddings = []\n","    for embedding in tqdm(document_vision_embeddings2):\n","        document_vision_embeddings.append(np.array(embedding))\n","    print(\"loaded embeddings\")\n","    query_embedding = single_unit_embedding(query)\n","    rankings, scores = vision_rankings(query_embedding, document_vision_embeddings, k)\n","    rankings2 = []\n","    for ranking in rankings:\n","        rankings2.append(ids[ranking])\n","    return rankings2"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [00:00<00:00, 34237.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["loaded embeddings\n"]},{"data":{"text/plain":["['48272667', '53470812', '50170741', '19865700', '39790870']"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["vision_pipeline(\"In the United States, why are positions like Attorney General, Secretary of State, etc. appointed by the president at the federal level but elected by the people at the state level? Had it ever been proposed to do this differently?\", 'document-vision-embeddings.json', 'ids.pkl', 5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3.10.12 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"vscode":{"interpreter":{"hash":"e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"}}},"nbformat":4,"nbformat_minor":4}
